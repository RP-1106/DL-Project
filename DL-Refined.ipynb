{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f4820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import CLIPTokenizer, CLIPTextModel\n",
    "from diffusers import AutoencoderKL, DDPMScheduler\n",
    "from PIL import Image\n",
    "from tensorflow_addons.layers.normalizations import GroupNormalization\n",
    "from ipynb.fs.full.model4 import UNetMidBlock2DCrossAttn\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def0ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CLIP text encoder\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"tokenizer\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"text_encoder\", use_safetensors=True)\n",
    "text_encoder.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8096b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "prompt = [\"A unicorn sitting on a rainbow\"]\n",
    "height = 512  # Set the desired height\n",
    "width = 512  # Set the desired width\n",
    "img_height=32\n",
    "img_width = 32\n",
    "num_inference_steps = 100  # Number of denoising steps\n",
    "guidance_scale = 3.5  # Scale for classifier-free guidance\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ff528",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model_path = \"model.h5\"  # Replace with the path to your model.pt\n",
    "model =tf.keras.models.load_model(model_path,custom_objects={\"GroupNormalization\": GroupNormalization,\n",
    "                                                             \"UNetMidBlock2DCrossAttn\": UNetMidBlock2DCrossAttn})         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb4719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text prompt and convert it to a PyTorch tensor\n",
    "text_input = tokenizer(\n",
    "    prompt,\n",
    "    padding=\"max_length\",\n",
    "    max_length=tokenizer.model_max_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b35316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    text_embeddings = text_encoder(text_input.input_ids.to(\"cuda\"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6640690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random latent noise image and normalize it\n",
    "latents = torch.randn(\n",
    "    (batch_size, height, width, 3),\n",
    "    device=\"cuda\",\n",
    ")\n",
    "latents = latents / 255.0  # Normalize the noise image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42733ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.image import resize\n",
    "latents = latents.cpu().numpy()\n",
    "latents = resize(latents, (height, width))\n",
    "latents = tf.convert_to_tensor(latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d2f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a diffusion schedulerfrom tensorflow.image import resize\n",
    "scheduler = DDPMScheduler.from_pretrained(\"google/ddpm-cat-256\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d43524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of denoising steps for the diffusion process\n",
    "scheduler.set_timesteps(num_inference_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89898f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_tensor(input_tensor, target_shape):\n",
    "\n",
    "    target_height, target_width, num_channels = target_shape[1], target_shape[2], target_shape[3]\n",
    "    input_tensor = tf.cast(input_tensor, dtype=tf.float32)\n",
    "    reshaped_tensor = tf.image.resize(input_tensor, (target_height, target_width))\n",
    "    reshaped_tensor = tf.image.resize_with_crop_or_pad(reshaped_tensor, target_height, target_width)\n",
    "    \n",
    "    return reshaped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a08cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_shape = (1, 512, 512, 3)\n",
    "input_tensor = tf.Variable(tf.zeros(original_shape, dtype=tf.float32))\n",
    "\n",
    "# Define the target shape\n",
    "target_shape = (None, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11815468",
   "metadata": {},
   "source": [
    "for t in range(num_inference_steps):\n",
    "    latents_tensor = reshape_tensor(input_tensor, target_shape)\n",
    "\n",
    "    # Predict the noise residual using your model\n",
    "    with tf.device(\"gpu:0\"):  # Assuming you want to use GPU\n",
    "        #latents_tensor = tf.reshape(latents, (1, -1, 1, 1))  # Use tf.reshape to reshape the tensor\n",
    "        noise_pred = model(latents_tensor,t) \n",
    "\n",
    "    latents_tensor = tf.reshape(latents_tensor, (1, 32, 32, 3))\n",
    "    noise_pred = tf.cast(noise_pred, dtype=tf.float32)\n",
    "    # Perform guidance\n",
    "    latents_tensor = tf.image.resize(latents_tensor, [32,32])\n",
    "    noise_pred = tf.reshape(noise_pred, (1, 32, 32, 1))\n",
    "\n",
    "    # Perform guidance\n",
    "    noise_pred = tf.image.resize(noise_pred, [32, 32])\n",
    "    noise_pred *= guidance_scale\n",
    "\n",
    "    # Resize latents to match the shape of model_output\n",
    "    latents = tf.image.resize(latents, [32, 32])\n",
    "    noise_pred = tf.cast(noise_pred, latents.dtype)\n",
    "    noise_pred = tf.clip_by_value(noise_pred, -1.0, 1.0)\n",
    "    \n",
    "    \n",
    "    # Compute the previous noisy sample x_t -> x_t-1\n",
    "    latents = scheduler.step(noise_pred, t, latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75395401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming 'input_tensor', 'latents', 'model', and 'scheduler' are TensorFlow objects\n",
    "for t in range(num_inference_steps):\n",
    "    # Convert 'input_tensor' to a PyTorch tensor\n",
    "    input_tensor_torch = torch.FloatTensor(input_tensor.numpy())\n",
    "\n",
    "    latents_tensor = reshape_tensor(input_tensor_torch, target_shape)\n",
    "\n",
    "    # Predict the noise residual using your model\n",
    "    with tf.device(\"gpu:0\"):  # Assuming you want to use GPU\n",
    "        noise_pred = model(latents_tensor, t)\n",
    "\n",
    "    latents_tensor = tf.reshape(latents_tensor, (1, 32, 32, 3))\n",
    "    noise_pred = tf.cast(noise_pred, dtype=tf.float32)\n",
    "    \n",
    "    # Perform guidance\n",
    "    latents_tensor = tf.image.resize(latents_tensor, [32, 32])\n",
    "    noise_pred = tf.reshape(noise_pred, (1, 32, 32, 1))\n",
    "\n",
    "    # Perform guidance\n",
    "    noise_pred = tf.image.resize(noise_pred, [32, 32])\n",
    "    noise_pred *= guidance_scale\n",
    "\n",
    "    # Convert 'latents' to a PyTorch tensor\n",
    "    latents = torch.FloatTensor(latents.numpy())\n",
    "\n",
    "    # Resize 'latents' to match the shape of model_output\n",
    "    latents = tf.image.resize(latents, [32, 32])\n",
    "    noise_pred = tf.cast(noise_pred, latents.dtype)\n",
    "    \n",
    "    # Clip 'noise_pred' if needed\n",
    "    noise_pred = tf.clip_by_value(noise_pred, -1.0, 1.0)\n",
    "\n",
    "    # Compute the previous noisy sample x_t -> x_t-1\n",
    "    latents = scheduler.step(noise_pred, t, latents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c268a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalize the image and convert it to a PIL image\n",
    "image = (latents * 255.0).clamp(0, 255).to(torch.uint8).cpu().numpy()\n",
    "image = Image.fromarray(image.squeeze())\n",
    "\n",
    "# Display the generated image\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d0a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2af2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276373c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
